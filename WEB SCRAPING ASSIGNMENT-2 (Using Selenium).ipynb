{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c831e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import selenium and webdriver\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa86f59",
   "metadata": {},
   "source": [
    "# Question 1. naukri.com -Data Analyst job details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fd12bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Network Design &amp; Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell International Services India Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens Limited</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bright Money</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Edubrigde</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst CX</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Security Specialist - CS Awareness &amp; Da...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zilingo.com</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                      Network Design & Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                                    Data Analyst CX   \n",
       "6                                Senior Data Analyst   \n",
       "7  Senior Security Specialist - CS Awareness & Da...   \n",
       "8                                      Data analysts   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4   Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bengaluru/Bangalore   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company Name Experience Required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1  Dell International Services India Private Limited             0-2 Yrs  \n",
       "2                                    Siemens Limited             0-5 Yrs  \n",
       "3                                       Bright Money             0-2 Yrs  \n",
       "4                                          Edubrigde             0-0 Yrs  \n",
       "5                              Philips India Limited            6-10 Yrs  \n",
       "6                  Flipkart Internet Private Limited             4-5 Yrs  \n",
       "7       Cognizant Technology Solutions India Pvt Ltd             4-7 Yrs  \n",
       "8                             IBM India Pvt. Limited             5-6 Yrs  \n",
       "9                                        Zilingo.com             0-4 Yrs  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the web page with given url\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "#lets find the place to enter skill,designation,companies\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "#Entre the designation \n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "#find place to enter job location\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#Enter location\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "#find path for search button and click on enter \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "time.sleep(8)\n",
    "\n",
    "job_titles = []\n",
    "location = []\n",
    "companies = []\n",
    "exp = []\n",
    "#lets find first 10 job titles\n",
    "titles_tag = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "\n",
    "for i in titles_tag:\n",
    "    job_titles.append(i.text)  \n",
    "job_titles\n",
    "\n",
    "#find first 10 job locations\n",
    "locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")[:10]\n",
    "\n",
    "for i in locations:\n",
    "    location.append(i.text)\n",
    "location\n",
    "#find first 10 company names\n",
    "company = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']//a[1]\")[:10]\n",
    "for i in company:\n",
    "    companies.append(i.text)\n",
    "companies\n",
    "\n",
    "#find required experience\n",
    "Experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")[:10]\n",
    "for i in Experience:\n",
    "    exp.append(i.text)\n",
    "exp\n",
    "\n",
    "\n",
    "\n",
    "#Let's create a Data-Frame for specified job information\n",
    "data = list(zip(job_titles,location,companies,exp))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns = [\"Job-Title\", \"Job-Location\", \"Company Name\", \"Experience Required\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebcdfc2",
   "metadata": {},
   "source": [
    "# Question 2. naukri.com Data Scientist job details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57371153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job description   Job description      Job Rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior/Lead Data Scientist - Machine Learning/...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Squareroot Consulting Pvt Ltd.</td>\n",
       "      <td>Job description   Roles and Responsibilities  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics3.9(97 Reviews)</td>\n",
       "      <td>Job description   The Artificial Intelligence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Vadodara</td>\n",
       "      <td>Nielsen3.8(485 Reviews)</td>\n",
       "      <td>Job description   ABOUT THIS JOB   NielsenIQ A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Job description   Roles and Responsibilities  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes - The Network4.0(238 Reviews)</td>\n",
       "      <td>Job description     Contributing in developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes Incorporated4.0(238 Reviews)</td>\n",
       "      <td>Job description   As a Data Scientist, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Consumer Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Eli Lilly and Company4.2(116 Reviews)</td>\n",
       "      <td>Job description   Core Responsibilities   Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANI Technologies Pvt Ltd (Olacabs)4.0(1213 Rev...</td>\n",
       "      <td>Job description   The Data Science Machine Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Senior/Lead Data Scientist - Machine Learning/...   \n",
       "2                              Senior Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                Data Scientist - Consumer Analytics   \n",
       "8                                   Data Scientist I   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "3             Chennai, Bangalore/Bengaluru, Vadodara   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company Name  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                     Squareroot Consulting Pvt Ltd.   \n",
       "2                   Fractal Analytics3.9(97 Reviews)   \n",
       "3                            Nielsen3.8(485 Reviews)   \n",
       "4                       Wrackle Technologies Pvt Ltd   \n",
       "5         Baker Hughes - The Network4.0(238 Reviews)   \n",
       "6          Baker Hughes Incorporated4.0(238 Reviews)   \n",
       "7              Eli Lilly and Company4.2(116 Reviews)   \n",
       "8  ANI Technologies Pvt Ltd (Olacabs)4.0(1213 Rev...   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job description   Job description      Job Rol...  \n",
       "1  Job description   Roles and Responsibilities  ...  \n",
       "2  Job description   The Artificial Intelligence ...  \n",
       "3  Job description   ABOUT THIS JOB   NielsenIQ A...  \n",
       "4  Job description   Roles and Responsibilities  ...  \n",
       "5  Job description     Contributing in developmen...  \n",
       "6  Job description   As a Data Scientist, you wou...  \n",
       "7  Job description   Core Responsibilities   Mode...  \n",
       "8  Job description   The Data Science Machine Lea...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the web page with given url\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url2)\n",
    "time.sleep(5)\n",
    "\n",
    "#lets find the place to enter skill,designation,companies\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "\n",
    "#Entre the designation \n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#find place to enter job location\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "#Enter location\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#find path for search button and click on enter \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "time.sleep(10)\n",
    "\n",
    "# find urls for every job \n",
    "urls = []\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "#fetching required data from every page\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "job_desc = []\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    #fetching job titles\n",
    "    try:\n",
    "        job = driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        job_title.append(job.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #fetch job location\n",
    "    try:\n",
    "        loc = driver.find_element_by_xpath(\"//span[@class='location ']\")\n",
    "        job_location.append(loc.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #fetch company name\n",
    "    try:\n",
    "        company = driver.find_element_by_xpath(\"//div[@class='jd-header-comp-name']\")\n",
    "        company_name.append(company.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #fetch full job description\n",
    "    try:\n",
    "        desc = driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_desc.append(desc.text.replace('\\n','   '))\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "#Creating DataFrame\n",
    "data = list(zip(job_title,job_location,company_name,job_desc))\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"Job-Title\", \"Job-Location\", \"Company Name\", \"Job Description\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d492e",
   "metadata": {},
   "source": [
    "# Question 3. naukri.com Data Scientist job details by applying filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b3182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst /Business Analyst</td>\n",
       "      <td>Pune, Delhi / NCR, Mumbai (All Areas)</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Analytics -Data Scientist</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad</td>\n",
       "      <td>ERM Placement Services (P) Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist (Early Joiner)</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0      Data Scientist/Data Analyst /Business Analyst   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2             Data Scientist - Machine Learning/ NLP   \n",
       "3                    Data Scientist || Python || C2H   \n",
       "4                    Data Scientist || Python || C2H   \n",
       "5                 Advanced Analytics -Data Scientist   \n",
       "6                      Data Scientist (Early Joiner)   \n",
       "7  Data analytics / Data scientist intern (work f...   \n",
       "8              Chaayos is Looking For Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0              Pune, Delhi / NCR, Mumbai (All Areas)   \n",
       "1                  Noida, Greater Noida, Delhi / NCR   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...   \n",
       "4  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...   \n",
       "5                  New Delhi, Hyderabad/Secunderabad   \n",
       "6                             Noida(Sector-59 Noida)   \n",
       "7          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "8                                          New Delhi   \n",
       "9      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                            Company Name Experience Required  \n",
       "0     Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1              GABA Consultancy services             0-0 Yrs  \n",
       "2                                 TalPro             2-6 Yrs  \n",
       "3               Growel Softech Pvt. Ltd.             4-6 Yrs  \n",
       "4               Growel Softech Pvt. Ltd.             4-6 Yrs  \n",
       "5        ERM Placement Services (P) Ltd.             3-7 Yrs  \n",
       "6           R Systems International Ltd.             4-8 Yrs  \n",
       "7                         TalkValley LLC             0-5 Yrs  \n",
       "8  Chaayos (Sunshine Teahouse Pvt. Ltd.)             0-5 Yrs  \n",
       "9                      Fractal Analytics             3-7 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "#lets find the place to enter skill,designation,companies\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "time.sleep(5)\n",
    "\n",
    "#find path for search button and click on enter \n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "time.sleep(5)\n",
    "\n",
    "loc_fltr = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i\")\n",
    "loc_fltr.click()\n",
    "time.sleep(5)\n",
    "sal_fltr = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i\")\n",
    "sal_fltr.click()\n",
    "time.sleep(8)\n",
    "\n",
    "job_titles = []\n",
    "job_loc = []\n",
    "company_name = []\n",
    "exp_required = []\n",
    "\n",
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "\n",
    "location = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")[:10]\n",
    "\n",
    "company = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']//a[1]\")[:10]\n",
    "\n",
    "exp = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "for i in job_title:\n",
    "    job_titles.append(i.text)\n",
    "job_titles\n",
    "\n",
    "for i in location:\n",
    "    job_loc.append(i.text)\n",
    "job_loc\n",
    "\n",
    "for i in company:\n",
    "    company_name.append(i.text)\n",
    "company_name\n",
    "\n",
    "for i in exp:\n",
    "    exp_required.append(i.text)\n",
    "exp_required\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#creating dataframe\n",
    "data = list(zip(job_titles,job_loc,company_name,exp_required))\n",
    "df = pd.DataFrame(data, columns = [\"Job Title\",\"Job Location\",\"Company Name\",\"Experience Required\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58305dd8",
   "metadata": {},
   "source": [
    "# Question 4. glassdoor Data Scientist job details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639728b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb48b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in = driver.find_element_by_xpath(\"//div[@class='d-flex justify-content-center order-1 order-md-2 LockedHomeHeaderStyles__flexibleContainer']//button\")\n",
    "sign_in.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b1459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets sign in using glassdoor ID\n",
    "email = driver.find_element_by_id(\"userEmail\")\n",
    "email.send_keys(\"abhinandankadam196@gmail.com\")\n",
    "\n",
    "pass_ = driver.find_element_by_id(\"userPassword\")\n",
    "pass_.send_keys(\"20132611\")\n",
    "\n",
    "enter = driver.find_element_by_xpath(\"//div[@class='mt-std d-flex flex-column align-items-center']//button\")\n",
    "enter.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03b452de",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = driver.find_element_by_id(\"sc.keyword\")\n",
    "job_title.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a83fdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_loc = driver.find_element_by_xpath(\"//div[@class='ml-xsm col-4 p-0 headerSearchInput SearchStyles__searchBarLocationInput css-1ohf0ui']//input\")\n",
    "job_loc.send_keys(\"Noida\")\n",
    "\n",
    "search = driver.find_element_by_xpath(\"/html/body/header/nav[1]/div/div/div/div[4]/div[3]/form/div/button\")\n",
    "search.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbf1adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>job posted time</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Patterns</td>\n",
       "      <td>21d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ginger Webs Pvt. Ltd.</td>\n",
       "      <td>25d</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wobb.ai</td>\n",
       "      <td>11d</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scymes Services Pvt. ltd</td>\n",
       "      <td>4d</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Algo8 AI Pvt. Ltd.</td>\n",
       "      <td>17d</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MasterCard</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>7d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name job posted time Company Rating\n",
       "0                  Ericsson             24h            4.1\n",
       "1             Data Patterns             21d            3.1\n",
       "2     Ginger Webs Pvt. Ltd.             25d               \n",
       "3                   Wobb.ai             11d               \n",
       "4  Scymes Services Pvt. ltd              4d               \n",
       "5            Biz2Credit Inc            30d+            3.9\n",
       "6        Algo8 AI Pvt. Ltd.             17d               \n",
       "7                     Crowe            30d+            3.8\n",
       "8                MasterCard              4d            4.3\n",
       "9        UnitedHealth Group              7d            3.7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetching required data \n",
    "name = []\n",
    "days = []\n",
    "ratings = []\n",
    "#fetching company names\n",
    "try:\n",
    "    c_name = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']//span\")\n",
    "    for i in c_name:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "#fetching days/time\n",
    "try:\n",
    "    no_of_days = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "    for i in no_of_days:\n",
    "        days.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "#fetching ratings\n",
    "try:\n",
    "    rating = driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-x75kgh e1rrn5ka3']\")\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "ratings\n",
    "names = name[0:30:3]\n",
    "#creating DataFrame\n",
    "data = list(zip(names,days,ratings))\n",
    "df = pd.DataFrame(data,columns = [\"Company Name\",\"job posted time\",\"Company Rating\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca89429",
   "metadata": {},
   "source": [
    "# Question 5. glassdoor Data Scientist salary details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80ca8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(5)\n",
    "\n",
    "#get the web page with given url\n",
    "url = \" https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "job = driver.find_element_by_id(\"KeywordSearch\")\n",
    "job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c13a61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element_by_id(\"LocationSearch\")\n",
    "loc.send_keys(\"Noida\")\n",
    "\n",
    "srch_btn = driver.find_element_by_id(\"HeroSearchButton\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "031f0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in = driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[1]/div/div/div/div/div[2]/div/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07854f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>₹9,00,000</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹27L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>17 salaries</td>\n",
       "      <td>₹6,15,289</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,63,336</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,18,244</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,39,238</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹13,19,140</td>\n",
       "      <td>₹11L</td>\n",
       "      <td>₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,63,750</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹13,28,697</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹22L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹11,42,356</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹18L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Number of Salaries Average Salary Min Salary  \\\n",
       "0                        IBM        18 salaries      ₹9,00,000        ₹6L   \n",
       "1  Tata Consultancy Services        17 salaries      ₹6,15,289        ₹3L   \n",
       "2                  Accenture        15 salaries     ₹11,63,336        ₹6L   \n",
       "3                  Delhivery        15 salaries     ₹12,18,244        ₹5L   \n",
       "4         Ericsson-Worldwide        14 salaries      ₹7,39,238        ₹4L   \n",
       "5         UnitedHealth Group        12 salaries     ₹13,19,140       ₹11L   \n",
       "6         Valiance Solutions        10 salaries      ₹8,63,750        ₹5L   \n",
       "7                EXL Service         9 salaries     ₹11,10,000        ₹6L   \n",
       "8     Optum Global Solutions         9 salaries     ₹13,28,697        ₹4L   \n",
       "9              ZS Associates         8 salaries     ₹11,42,356        ₹2L   \n",
       "\n",
       "  Max Salary  \n",
       "0       ₹27L  \n",
       "1       ₹13L  \n",
       "2       ₹22L  \n",
       "3       ₹1Cr  \n",
       "4       ₹16L  \n",
       "5       ₹15L  \n",
       "6       ₹15L  \n",
       "7       ₹15L  \n",
       "8       ₹22L  \n",
       "9       ₹18L  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets sign in using glassdoor ID\n",
    "email = driver.find_element_by_id(\"userEmail\")\n",
    "email.send_keys(\"abhinandankadam196@gmail.com\")\n",
    "\n",
    "pass_ = driver.find_element_by_id(\"userPassword\")\n",
    "pass_.send_keys(\"20132611\")\n",
    "\n",
    "entre_btn = driver.find_element_by_xpath(\"//button[@class='gd-ui-button minWidthBtn css-8i7bc2']\").click()\n",
    "time.sleep(8)\n",
    "\n",
    "#fetching required data\n",
    "min_sal = []\n",
    "max_sal = []\n",
    "company = []\n",
    "avg_sal = []\n",
    "rating = []\n",
    "num_salary=[]\n",
    "\n",
    "\n",
    "#fetching min salary\n",
    "try:\n",
    "    min_ = driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']//p[1]\")[:10]\n",
    "    for i in min_:\n",
    "        min_sal.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "min_sal\n",
    "\n",
    "#fetching max salary\n",
    "try:\n",
    "    max_ = driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']//p[2]\")[:10]\n",
    "    for i in max_:\n",
    "        max_sal.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "max_sal\n",
    "\n",
    "#fetching company names\n",
    "try:\n",
    "    cmpny = driver.find_elements_by_xpath(\"//h3[@class='m-0 css-g261rn']//a\")[:10]\n",
    "    for i in cmpny:\n",
    "        company.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "company[:10]\n",
    "\n",
    "#fetching average salary\n",
    "try:\n",
    "    avg = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']//h3\")[:10]\n",
    "    for i in avg:\n",
    "        avg_sal.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "avg_sal\n",
    "#fetching number of salaries\n",
    "try:\n",
    "    n_sal = driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']//span\")\n",
    "    for i in n_sal:\n",
    "        num_salary.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "#creating a DataFrame\n",
    "data = list(zip(company,num_salary,avg_sal,min_sal,max_sal))\n",
    "df = pd.DataFrame(data, columns = [\"Company Name\",\"Number of Salaries\",\"Average Salary\",\"Min Salary\",\"Max Salary\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d62b1e",
   "metadata": {},
   "source": [
    "# Question 6.  flipkart sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6869586d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (49)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹682</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (58)</td>\n",
       "      <td>₹899</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹592</td>\n",
       "      <td>34% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description Price  \\\n",
       "0        ROYAL SON     Polarized, UV Protection Round Sunglasses (49)  ₹664   \n",
       "1        ROYAL SON                   Mirrored Aviator Sunglasses (55)  ₹379   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹682   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹513   \n",
       "4   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹299   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON             Polarized Retro Square Sunglasses (58)  ₹899   \n",
       "96      PHENOMENAL  UV Protection Retro Square Sunglasses (Free Size)  ₹399   \n",
       "97        Fastrack       UV Protection Aviator Sunglasses (Free Size)  ₹592   \n",
       "98        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹499   \n",
       "99       ROYAL SON  Polarized, UV Protection Retro Square Sunglass...  ₹664   \n",
       "\n",
       "   Discount  \n",
       "0   66% off  \n",
       "1   74% off  \n",
       "2   24% off  \n",
       "3   35% off  \n",
       "4   88% off  \n",
       "..      ...  \n",
       "95  55% off  \n",
       "96  80% off  \n",
       "97  34% off  \n",
       "98  37% off  \n",
       "99  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "cancel = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "cancel.click()\n",
    "\n",
    "search = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\")\n",
    "\n",
    "search.send_keys(\"sunglasses\")\n",
    "\n",
    "search_icon = driver.find_element_by_tag_name(\"svg\")\n",
    "search_icon.click()\n",
    "time.sleep(5)\n",
    "#fetch required data\n",
    "brand_name = []\n",
    "description = []\n",
    "prices = []\n",
    "discounts = []\n",
    "for i in range(0,4):\n",
    "    try:\n",
    "        brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "        for i in brand:\n",
    "            brand_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        P_dsc = driver.find_elements_by_class_name(\"IRpwTa\")     #product description\n",
    "        for i in P_dsc:\n",
    "            description.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    try:\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")  #prices\n",
    "        for i in price:\n",
    "            prices.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    try:\n",
    "        discount = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")   #discounts\n",
    "        for i in discount:\n",
    "            discounts.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "time.sleep(5)        \n",
    "next_page = driver.find_element_by_class_name(\"_1LKTO3\")   #link to fetch next page\n",
    "next_page.click()\n",
    "time.sleep(8)\n",
    "\n",
    "#creating a dataframe\n",
    "data = list(zip(brand_name,description,prices,discounts))\n",
    "df = pd.DataFrame(data,columns=[\"Brand\",\"Product Description\",\"Price\",\"Discount\"])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7002cc",
   "metadata": {},
   "source": [
    "# Question 7.  flipkart iphone-11 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420a1d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5   Worth every penny   \n",
       "3       5           Fabulous!   \n",
       "4       5       Great product   \n",
       "..    ...                 ...   \n",
       "95      5      Simply awesome   \n",
       "96      4         Good choice   \n",
       "97      5   Worth every penny   \n",
       "98      5  Highly recommended   \n",
       "99      5    Perfect product!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "..                                                ...  \n",
       "95  Really satisfied with the Product I received.....  \n",
       "96  So far it’s been an AMAZING experience coming ...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  iphone 11 is a very good phone to buy only if ...  \n",
       "99  It’s a must buy who is looking for an upgrade ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "All = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']//span\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "#fetching required data\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "full_review = []\n",
    "for i in range(0,10):\n",
    "    \n",
    "    try : \n",
    "        rating = driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for i in rating:\n",
    "            Rating.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "    try: \n",
    "        shrt_review = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in shrt_review:\n",
    "            Review_summary.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "    try:\n",
    "        f_review = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "        for i in f_review:\n",
    "            full_review.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "next_page = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]\").click()\n",
    "time.sleep(10)\n",
    "\n",
    "data = list(zip(Rating,Review_summary,full_review))\n",
    "df = pd.DataFrame(data, columns = [\"Rating\", \"Review Summary\", \"Full Review\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068b007",
   "metadata": {},
   "source": [
    "# Question 8. flipkart- sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd62c666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baogi</td>\n",
       "      <td>Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Green Shoes For Men And Boys S...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Green Shoes For Men And Boys S...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>LEBRON 2.0 Sneakers For Men</td>\n",
       "      <td>₹2,199</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                Product Description  \\\n",
       "0             Baogi                     Shoes For Men Sneakers For Men   \n",
       "1      Robbie jones  Casual Sneakers Green Shoes For Men And Boys S...   \n",
       "2      Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "3          CALCADOS  Modern Trendy Shoes Combo pack of 4 Sneakers F...   \n",
       "4          ASTEROID  Original Luxury Branded Fashionable Men's Casu...   \n",
       "..              ...                                                ...   \n",
       "95           BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...   \n",
       "96           Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "97     Robbie jones  Casual Sneakers Green Shoes For Men And Boys S...   \n",
       "98          Numenzo                                   Sneakers For Men   \n",
       "99  U.S. POLO ASSN.                        LEBRON 2.0 Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹399  60% off  \n",
       "1     ₹499  50% off  \n",
       "2     ₹379  62% off  \n",
       "3     ₹748  62% off  \n",
       "4     ₹499  75% off  \n",
       "..     ...      ...  \n",
       "95    ₹474  86% off  \n",
       "96    ₹599  62% off  \n",
       "97    ₹499  50% off  \n",
       "98    ₹449  77% off  \n",
       "99  ₹2,199  45% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.flipkart.com\"\n",
    "driver.get(url)\n",
    "cancel = driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "cancel.click()\n",
    "time.sleep(5)\n",
    "\n",
    "search = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\")\n",
    "search.send_keys(\"sneakers\")\n",
    "\n",
    "search_icon = driver.find_element_by_tag_name(\"svg\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "#fetching required data\n",
    "brand_name = []\n",
    "description = []\n",
    "prices = []\n",
    "discounts = []\n",
    "for i in range(0,3):\n",
    "    try:\n",
    "        brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\") #brand name\n",
    "        for i in brand:\n",
    "            brand_name.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "    try:\n",
    "        desc = driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a[1]\") #description\n",
    "        for i in desc:\n",
    "            description.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "    try:\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")  #price\n",
    "        for i in price:\n",
    "            prices.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "    try:\n",
    "        discount = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")  #discoundt\n",
    "        for i in discount:\n",
    "            discounts.append(i.text)\n",
    "    except NoSuchElementException: \n",
    "        pass\n",
    "next_page = driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "time.sleep(8)\n",
    "\n",
    "#creating dataframe\n",
    "data = list(zip(brand_name,description,prices,discounts))\n",
    "df = pd.DataFrame(data,columns=[\"Brand\",\"Product Description\",\"Price\",\"Discount\"])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aac1ba",
   "metadata": {},
   "source": [
    "# Question 9. myntra-shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e5d765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 8236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Winflo 8 Running</td>\n",
       "      <td>Rs. 12316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 12316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM PEGASUS 38 Run</td>\n",
       "      <td>Rs. 8046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex LEBRON XVIII Basketball</td>\n",
       "      <td>Rs. 8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>Rs. 7696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Formal Leather Slip-Ons</td>\n",
       "      <td>Rs. 7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KIPRUN By Decathlon</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>Rs. 9749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 7857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Women Peep Toe Heels</td>\n",
       "      <td>Rs. 9749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                  Product Description      Price\n",
       "0                  Nike           Men AIR ZOOM Running Shoes   Rs. 8236\n",
       "1                  Nike            Men Zoom Winflo 8 Running  Rs. 12316\n",
       "2                  ALDO                    Men Driving Shoes  Rs. 12316\n",
       "3                  Nike          Men AIR ZOOM PEGASUS 38 Run   Rs. 8046\n",
       "4                  Nike       Unisex LEBRON XVIII Basketball   Rs. 8799\n",
       "..                  ...                                  ...        ...\n",
       "95                 Geox                        Women Sandals   Rs. 7696\n",
       "96                 Nike          Men Formal Leather Slip-Ons   Rs. 7699\n",
       "97  KIPRUN By Decathlon  Men Textured Formal Leather Loafers   Rs. 9749\n",
       "98                 Puma            Men Leather Formal Derbys   Rs. 7857\n",
       "99         Hush Puppies                 Women Peep Toe Heels   Rs. 9749\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "\n",
    "#applying filters\n",
    "clr_fltr = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "clr_fltr.click()\n",
    "time.sleep(3)\n",
    "\n",
    "price_fltr = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_fltr.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "#fetching required data\n",
    "brand_name = []\n",
    "description = []\n",
    "prices = []\n",
    "for i in range(0,5):\n",
    "    brand = driver.find_elements_by_tag_name(\"h3\")\n",
    "    shoe_dsc = driver.find_elements_by_class_name(\"product-product\")\n",
    "    price = driver.find_elements_by_class_name(\"product-discountedPrice\")\n",
    "    for i in brand:\n",
    "        brand_name.append(i.text)\n",
    "    for i in shoe_dsc:\n",
    "        description.append(i.text)\n",
    "    for i in price:\n",
    "        prices.append(i.text)\n",
    "next_page = driver.find_element_by_xpath(\"//li[@class='pagination-next']//a\")\n",
    "next_page.click()\n",
    "time.sleep(8)\n",
    "\n",
    "#creating dataframe\n",
    "data = list(zip(brand_name,description,prices))\n",
    "df = pd.DataFrame(data,columns=[\"Brand\",\"Product Description\",\"Price\"])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa8234",
   "metadata": {},
   "source": [
    "# Question 10. amazon - Laptops by applying icore7 & icore9 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "108b3d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop-Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>₹ 91,790.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "      <td>₹ 84,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹ 67,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>₹ 97,454.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹ 86,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹ 59,999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>₹ 1,75,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "      <td>₹ 78,993.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Gaming(2021) 10th Gen Intel Core i...</td>\n",
       "      <td>3 out of 5</td>\n",
       "      <td>₹ 91,990.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>₹ 76,990.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop-Title        Rating  \\\n",
       "0  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...  4.5 out of 5   \n",
       "1  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.5 out of 5   \n",
       "2  Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...  4.3 out of 5   \n",
       "3  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...  4.1 out of 5   \n",
       "4  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  4.2 out of 5   \n",
       "5  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5   \n",
       "6  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...    4 out of 5   \n",
       "7  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...  3.9 out of 5   \n",
       "8  HP Pavilion Gaming(2021) 10th Gen Intel Core i...    3 out of 5   \n",
       "9  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...  4.4 out of 5   \n",
       "\n",
       "           Price  \n",
       "0    ₹ 91,790.00  \n",
       "1    ₹ 84,990.00  \n",
       "2    ₹ 67,990.00  \n",
       "3    ₹ 97,454.00  \n",
       "4    ₹ 86,990.00  \n",
       "5    ₹ 59,999.00  \n",
       "6  ₹ 1,75,000.00  \n",
       "7    ₹ 78,993.00  \n",
       "8    ₹ 91,990.00  \n",
       "9    ₹ 76,990.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\ABHINANDAN\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#get the web page with given url\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "#lets search for laptop data on amazon\n",
    "search = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search.send_keys(\"Laptop\")\n",
    "\n",
    "search_btn = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_btn.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#apply mentioned filters\n",
    "fltr1 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[26]/span/a\") \n",
    "fltr1.click()\n",
    "time.sleep(3)\n",
    "\n",
    "fltr2 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[5]/ul[1]/li[28]/span/a/div/label/i\")\n",
    "fltr2.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#getting all urls for each laptop\n",
    "urls = []\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "titles = []\n",
    "ratings = []\n",
    "prices = []\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    #fetching title of laptop\n",
    "    try:\n",
    "        title = driver.find_element_by_id(\"productTitle\")\n",
    "        titles.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #fetching rating of laptop\n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        ratings.append(rating.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #fetching prices of laptops\n",
    "    try:\n",
    "        price = driver.find_element_by_xpath(\"//td[@class='a-span12']\") \n",
    "        prices.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        pass   \n",
    "time.sleep(5)\n",
    "#Creating DataFrame\n",
    "data = list(zip(titles,ratings,prices))\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"Laptop-Title\", \"Rating\", \"Price\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0f34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
